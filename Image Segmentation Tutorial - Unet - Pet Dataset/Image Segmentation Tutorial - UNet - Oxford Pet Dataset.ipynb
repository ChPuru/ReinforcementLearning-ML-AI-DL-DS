{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSA1CoISBaI4"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbZxWvknAVjE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bawx8gY7B02o"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFUjU9OBAXUf"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet', with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diAYmAe8C6nv",
        "outputId": "f8f84e4e-cc26-4853-e882-e1dc5d487a6a"
      },
      "outputs": [],
      "source": [
        "info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09EOLyIYDHVm",
        "outputId": "001eed66-b1e7-4842-b168-382fbb544e67"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKQdiL4RCl6u"
      },
      "source": [
        "## Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUns0vZHAXSg"
      },
      "outputs": [],
      "source": [
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = input_mask - 1 # convert to zero based indexing\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_train_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # data augmentation\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_test_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StJX7EpjAXQX"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train'].map(load_train_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = dataset['test'].map(load_test_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3mythw_E-eP"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XnZvfaCFjYe"
      },
      "source": [
        "## Explanatory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Br3pduRAXOp"
      },
      "outputs": [],
      "source": [
        "def display_sample(image_list):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(image_list)):\n",
        "        plt.subplot(1, len(image_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(image_list[i]))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KrBm2DhBAXMf",
        "outputId": "2410655e-f100-4df2-b29e-e7315aee6d63"
      },
      "outputs": [],
      "source": [
        "for images, masks in train_dataset.take(3):\n",
        "    sample_image, sample_mask = images[0], masks[0]\n",
        "    display_sample([sample_image, sample_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zMzQWWHA5v"
      },
      "source": [
        "## Define U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CckIxR4AXKn"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "    return x\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    f = double_conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.3)(p)\n",
        "    return f, p\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding='same')(x)\n",
        "    x = layers.concatenate([x, conv_features])\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = double_conv_block(x, n_filters)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyY8DdKcAXIw"
      },
      "outputs": [],
      "source": [
        "def build_unet_model(output_channels):\n",
        "    # input layer\n",
        "    inputs = layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "    # encoder - downsample\n",
        "    f1, p1 = downsample_block(inputs, 64)\n",
        "    f2, p2 = downsample_block(p1, 128)\n",
        "    f3, p3 = downsample_block(p2, 256)\n",
        "    f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "    # intermediate block\n",
        "    intermediate_block = double_conv_block(p4, 1024)\n",
        "\n",
        "    # decoder - upsample\n",
        "    u6 = upsample_block(intermediate_block, f4, 512)\n",
        "    u7 = upsample_block(u6, f3, 256)\n",
        "    u8 = upsample_block(u7, f2, 128)\n",
        "    u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "    # output layer\n",
        "    outputs = layers.Conv2D(output_channels, 1, padding='same', activation='softmax')(u9)\n",
        "\n",
        "    # unet model\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name='U-Net')\n",
        "\n",
        "    return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs_8WfwIJzl2"
      },
      "outputs": [],
      "source": [
        "# for images, masks in train_dataset.take(1):\n",
        "#     sample_image, sample_mask = images[0], masks[0]\n",
        "# sample_mask[60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DijP42IcAXGv"
      },
      "outputs": [],
      "source": [
        "output_channels = 3\n",
        "model = build_unet_model(output_channels)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0C8AaXo_AXFH",
        "outputId": "3cfe09a9-960d-4cb1-a486-b8fb094ec881"
      },
      "outputs": [],
      "source": [
        "# plot the model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=False, dpi=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUVil4bMcq-"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrN12gUNAXC_",
        "outputId": "6f0d3f4c-8e23-4a04-e75c-9303dbf1bf25"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "steps_per_epoch = info.splits['train'].num_examples // BATCH_SIZE\n",
        "validation_steps = info.splits['test'].num_examples // BATCH_SIZE\n",
        "\n",
        "history = model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O59xIVRMRLOo"
      },
      "source": [
        "## Visualize the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "k_NIOS9CAXBY",
        "outputId": "8b082187-32e5-4b5c-fd0e-8fb2f3fccf16"
      },
      "outputs": [],
      "source": [
        "# plot train & val accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "# plot train & val loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCNhferJR_Mv"
      },
      "source": [
        "## Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF62wx2WAW_n"
      },
      "outputs": [],
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = model.predict(image)\n",
        "            display_sample([image[0], mask[0], create_mask(pred_mask)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bJW__DhAW9v"
      },
      "outputs": [],
      "source": [
        "# for image, mask in test_dataset.take(1):\n",
        "#     pred_mask = model.predict(image)\n",
        "# pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "# print(np.array(pred_mask.shape))\n",
        "# pred_mask = pred_mask[..., tf.newaxis]\n",
        "# print(pred_mask[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vDkpbuyvAWvf",
        "outputId": "5ce4c134-9367-4c9c-ce5b-c1eb1864c796"
      },
      "outputs": [],
      "source": [
        "show_predictions(test_dataset, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz-Q-yEIAWuX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjMibCPwAWrY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
